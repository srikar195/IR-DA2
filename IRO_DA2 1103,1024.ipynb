{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKT8swLqQDRi",
        "outputId": "8f5db772-72a2-4bcf-b1e1-fe66a1ac8a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define document\n",
        "doc_1 = \"Every year Maha Shivratri is celebrated with a lot of pomp and grandeur. It is considered to be a very special time of the year since millions of people celebrate this momentous occasion with a lot of fervour and glee.\"\n",
        "doc_2 = \"Lord Shiva devotees celebrate this occasion with a lot of grandness. It is accompanied by folk dances,songs, prayers, chants, mantras etc. This year,the beautiful occasion of Maha Shivratri will be celebrated on February 18.\"\n",
        "doc_3 = \"People keep a fast on this Maha shivratri, stay awake at night and pray to the lord for blessings,happiness, hope and prosperity. This festival holds a lot of significance and is considered to be one of the most important festivals in India\"\n",
        "doc_4 = \"The festival of Maha Shivratri will be celebrated on February 18 and is a very auspicious festival. This Hindu festival celebrates the power of Lord Shiva. Lord Shiva protects his devotees from negative and evil spirits. He is the epitome of powerful and auspicious energy\"\n",
        "documents = [doc_1,doc_2,doc_3,doc_4]"
      ],
      "metadata": {
        "id": "3wc8768SQRvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizeing  the documents\n",
        "#Tokenization is the process of replacing sensitive data with unique identification symbols \n",
        "#that retain all the essential information about the data without compromising its security.\n",
        "tokenized_docs = []\n",
        "for doc in documents:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    tokenized_docs.append(tokens)"
      ],
      "metadata": {
        "id": "mGs7MPRGQsiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defineing  the vocabulary\n",
        "vocab = set()\n",
        "for tokens in tokenized_docs:\n",
        "    for word in tokens:\n",
        "        vocab.add(word)"
      ],
      "metadata": {
        "id": "x8iJxpXRQzlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatizeing  the tokens\n",
        "#Lemmatisation (or lemmatization) in linguistics is the process of grouping together\n",
        "#the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form.\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_docs = []\n",
        "for tokens in tokenized_docs:\n",
        "    lemmatized_tokens = []\n",
        "    for token in tokens:\n",
        "        lemmatized_token = lemmatizer.lemmatize(token)\n",
        "        lemmatized_tokens.append(lemmatized_token)\n",
        "    lemmatized_docs.append(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "Cd5AgGkuQt-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculateing the term frequency for each document\n",
        "tf = []\n",
        "for doc in lemmatized_docs:\n",
        "    doc_tf = {}\n",
        "    for word in doc:\n",
        "        if word in doc_tf:\n",
        "            doc_tf[word] += 1\n",
        "        else:\n",
        "            doc_tf[word] = 1\n",
        "    tf.append(doc_tf)"
      ],
      "metadata": {
        "id": "LjTr9UUaQ6fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculateing the inverse document frequency for each term in the vocabulary\n",
        "idf = {}\n",
        "N = len(documents)\n",
        "epsilon = 1e-6 \n",
        "for word in vocab:\n",
        "    n = sum([1 for doc in lemmatized_docs if word in doc])\n",
        "    idf[word] = math.log(N/(n + epsilon))\n",
        "    "
      ],
      "metadata": {
        "id": "pP8faDjvQ6Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculateing  the tf-idf for each document\n",
        "tf_idf = []\n",
        "for i in range(N):\n",
        "    doc_tf_idf = {}\n",
        "    doc_tf = tf[i]\n",
        "    for word in doc_tf:\n",
        "        if word in idf:\n",
        "            doc_tf_idf[word] = doc_tf[word] * idf[word]\n",
        "    tf_idf.append(doc_tf_idf)"
      ],
      "metadata": {
        "id": "xikGzPtyQ6M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the  query\n",
        "query = input(\"Maha Shivratri will be celebrated on February\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfUhnsBwRaUn",
        "outputId": "9a71ffde-0f6e-4ed4-f6fe-cf45a72c8c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maha Shivratri will be celebrated on February18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculateing  the tf-idf for the query\n",
        "query_tf_idf = {}\n",
        "query_words = query.split()\n",
        "for word in query_words:\n",
        "    if word in query_tf_idf:\n",
        "        query_tf_idf[word] += 1\n",
        "    else:\n",
        "        query_tf_idf[word] = 1\n",
        "for word in query_tf_idf:\n",
        "    if word in idf:\n",
        "        query_tf_idf[word] *= idf[word]\n",
        "        "
      ],
      "metadata": {
        "id": "RpZWzlKnRlKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defineing  a function to calculate the cosine similarity between document and query\n",
        "def cosine_similarity(set1, set2):\n",
        "    dot = sum([set1[word] * set2[word] for word in set1 if word in set2])\n",
        "    norm_doc = math.sqrt(sum([set1[word]**2 for word in set1]))\n",
        "    norm_query = math.sqrt(sum([set2[word]**2 for word in set2]))\n",
        "    return dot/ (norm_doc * norm_query)"
      ],
      "metadata": {
        "id": "YzlST7f5wTkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definein a function to calculate the Jaccard similarity between two documents\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)"
      ],
      "metadata": {
        "id": "xum4rPN0Rxpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the cosine similarity between the query and each document\n",
        "cosine_similarities = []\n",
        "for i in range(N):\n",
        "    cosine_similarities.append(cosine_similarity(query_tf_idf, tf_idf[i]))\n",
        "\n",
        "# the Jaccard similarity between the query and each document\n",
        "jaccard_similarities = []\n",
        "for i in range(N):\n",
        "    jaccard_similarities.append(jaccard_similarity(set(query_words), set(documents[i].split())))"
      ],
      "metadata": {
        "id": "b9Mb1WJUw_yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting the cosine similarities in descending order and printing  the top two documents\n",
        "\n",
        "cosine_similarities_sorted = sorted(range(len(cosine_similarities)), key=lambda i: cosine_similarities[i], reverse=True)\n",
        "print(\"Top two documents by cosine similarity:\")\n",
        "for i in range(2):\n",
        "    print(\"Document {}: {}\".format(cosine_similarities_sorted[i]+1, cosine_similarities[cosine_similarities_sorted[i]]))\n",
        "\n",
        "# Sort the Jaccard similarities in descending order and print the top two documents\n",
        "jaccard_similarities_sorted = sorted(range(len(jaccard_similarities)), key=lambda i: jaccard_similarities[i], reverse=True)\n",
        "print(\"Top two documents by Jaccard similarity:\")\n",
        "for i in range(2):\n",
        "    print(\"Document {}: {}\".format(jaccard_similarities_sorted[i]+1, jaccard_similarities[jaccard_similarities_sorted[i]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MUp-2bQUm5m",
        "outputId": "3b858704-c72c-4142-ce11-19d2813f6d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two documents by cosine similarity:\n",
            "Document 2: 0.12595463835235884\n",
            "Document 4: 0.1046909068624883\n",
            "Top two documents by Jaccard similarity:\n",
            "Document 4: 0.027777777777777776\n",
            "Document 1: 0.0\n"
          ]
        }
      ]
    }
  ]
}